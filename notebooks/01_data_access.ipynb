{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25045498-92c8-4aed-9443-8559b213bacc",
   "metadata": {},
   "source": [
    "# Earth Observation data handling using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c581c",
   "metadata": {},
   "source": [
    "## 00 - Generics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3841e418-8218-44ba-b067-d03b8e4afe40",
   "metadata": {},
   "source": [
    "### Add project directory to Python path\n",
    "\n",
    "This code defines two functions and retrieves the project directory path. It's useful when we want to define some generic functions that can be imported. If you retrieve the project directoy path like this, it both works in an Ipython and Python environment. \n",
    "\n",
    "- `is_interactive()`: Checks if the code is running in an interactive environment.\n",
    "- `get_proj_dir()`: Determines the project directory path based on the execution context. If running interactively, it infers the project directory from the Jupyter kernel. Otherwise, it infers it from the Python file. The function returns the project directory as a `pathlib.Path` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a318014-bea5-41f6-8453-8b8464f45286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "\n",
    "def is_interactive() -> bool:\n",
    "    \"\"\"\n",
    "    Check if the Python code is running in an interactive environment.\n",
    "    \"\"\"\n",
    "    import __main__ as main\n",
    "\n",
    "    return not hasattr(main, \"__file__\")\n",
    "\n",
    "\n",
    "def get_proj_dir() -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Get the project directory path.\n",
    "\n",
    "    Returns:\n",
    "        A `pathlib.Path` object representing the project directory path.\n",
    "    \"\"\"\n",
    "    if is_interactive():\n",
    "        print(\"Inferring project directory from the Jupyter kernel.\")\n",
    "        cwd = pathlib.Path().resolve()\n",
    "        proj_dir = cwd.parent\n",
    "    else:\n",
    "        print(\"Inferring project directory from the Python file.\")\n",
    "        cwd = pathlib.Path(__file__)\n",
    "        proj_dir = cwd.parent.parent\n",
    "\n",
    "    return proj_dir\n",
    "\n",
    "\n",
    "proj_dir: pathlib.Path = get_proj_dir()\n",
    "sys.path.append(str(proj_dir / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f4928-8baa-4864-aea5-5af00a6078fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proj_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9adea-ab8e-4c20-bbea-2e7a8b4bc169",
   "metadata": {},
   "source": [
    "### Very extensive list of libraries - I'll cleanup later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee46249-33ee-4c65-85af-d27d37f81a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "import cartopy.crs as crs\n",
    "\n",
    "# import adlfs\n",
    "# import azure.storage.blob\n",
    "import colorcet as cc\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# import dask_gateway\n",
    "import dask_geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "# import geoviews.tile_sources as gvts\n",
    "import holoviews as hv\n",
    "import hvplot.pandas  # noqa\n",
    "import hvplot.xarray  # noqa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import planetary_computer\n",
    "import pooch\n",
    "import pyproj\n",
    "import pystac\n",
    "import pystac_client\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import rioxarray as rio\n",
    "import shapely\n",
    "import stackstac\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "\n",
    "# from azure.storage.blob import BlobServiceClient\n",
    "from dask.distributed import Client\n",
    "from geopandas.array import GeometryDtype\n",
    "from ipyleaflet import Map, basemaps\n",
    "from matplotlib.colors import ListedColormap\n",
    "from odc.stac import configure_rio, stac_load\n",
    "from xrspatial.multispectral import true_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240ec0c",
   "metadata": {},
   "source": [
    "## 01 - Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb38b6-307d-433f-aff7-b796a140788a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = Map(basemap=basemaps.Esri.WorldImagery, scroll_wheel_zoom=True)\n",
    "m.center = 52.058, 4.192\n",
    "m.zoom = 14\n",
    "m.layout.height = \"800px\"\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413be0d-b95f-4545-9077-a885f84f5009",
   "metadata": {},
   "source": [
    "### EO team discussion point \n",
    "\n",
    "Do we show how to import generic functions from a project directory? Otherwise I'll just redefine the functions here in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587a186-9f4c-410e-b1c5-9fc544649325",
   "metadata": {},
   "source": [
    "### Extract the coords from the interactive map -- IMPORTANT: wait 2 seconds until map is rendered, othewise you cannot extract the coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7aeb-a1ae-42b1-8cb3-01393d9ecead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from coastmonitor.geo.geometries import bbox_to_geometry, geo_bbox, geometry_to_bbox\n",
    "\n",
    "bbox = [m.west, m.south, m.east, m.north]\n",
    "bbox_geom = bbox_to_geometry(bbox)\n",
    "geo_bbox(*bbox, src_crs=4326, dst_crs=4326).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61566c9-0bae-490e-836f-999b95deb8a5",
   "metadata": {},
   "source": [
    "### Connect to the planetary STAC catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702235e-6871-4a40-99f0-cb09e51a01ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381a239-7eaa-4436-96f4-a38e72501f26",
   "metadata": {},
   "source": [
    "### EO Discussion\n",
    "Floris: cell below breaks on my machine with APIError. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff409d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list(\n",
    "#     catalog.get_children()\n",
    "# )  # list all the STAC Collections (i.e. datasets hosted by planetary computer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66276fe4-2437-4d09-a937-7428183c4608",
   "metadata": {},
   "source": [
    "### Browse the STAC catalog \n",
    "Search the Sentinel-2 SR catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557919de-f315-4b15-8c0e-cc8b86753f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BAND = {\n",
    "    \"B02\": \"blue\",\n",
    "    \"B03\": \"green\",\n",
    "    \"B04\": \"red\",\n",
    "    \"B08\": \"nir\",\n",
    "    \"B11\": \"swir1\",\n",
    "    \"SCL\": \"SCL\",\n",
    "}\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=[\n",
    "        \"sentinel-2-l2a\"\n",
    "    ],  # atmospherically corrected Surface Reflectances (SR)\n",
    "    intersects=bbox_geom,\n",
    "    datetime=\"2022-12-31/2023-05-01\",  # \"2020-01-01/2020-01-31\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 50}},\n",
    ")\n",
    "\n",
    "items = search.item_collection()\n",
    "print(f\"{len(items)} items found in catalog search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6fa74-724e-4da5-8e2d-5df8cbb55276",
   "metadata": {},
   "source": [
    "### Planetary computer STAC catalog\n",
    "\n",
    "Microsoft Planetary Computer much more data; see [the catalog in the radiant earth STAC viewer](https://radiantearth.github.io/stac-browser/#/external/planetarycomputer.microsoft.com/api/stac/v1?.language=en). Other catalogs are the [C-Scale metadata federation](https://radiantearth.github.io/stac-browser/#/external/mqs.eodc.eu/stac/v1), [Digital Earth Africa (DEA)](https://radiantearth.github.io/stac-browser/#/external/explorer.digitalearth.africa/stac?.language=en) or [the Deltares CoCliCo](https://radiantearth.github.io/stac-browser/#/external/storage.googleapis.com/dgds-data-public/coclico/coclico-stac/catalog.json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22d204b-4efa-44ba-9f3f-aacd65258b9c",
   "metadata": {},
   "source": [
    "### Explain a STAC item here\n",
    "\n",
    "- you can filter the STAC collection on all metadata that is shown here\n",
    "- the asset contains several keys which refer to where the data is stored for the bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935cbe8-7464-4ad4-9970-7f6864f2c607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f31c0-404f-4c62-b585-e24f7578d644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items[0].assets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd47c2-447a-4201-bea9-5d7f9b74f9c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "href = items[0].assets[\"rendered_preview\"].href\n",
    "href"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e435a1-5240-4b5a-9d3f-4267d170c3f6",
   "metadata": {},
   "source": [
    "### Show the preview in your python notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94384243-1889-4393-b5a7-016f5918c3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the image from the URL\n",
    "image = plt.imread(io.BytesIO(urllib.request.urlopen(href).read()))\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdab1b8-ff75-4d98-96b4-962b346c2c3d",
   "metadata": {},
   "source": [
    "### EO team TODO: \n",
    "\n",
    "It's better to read the data with Xarray (then we actually have the data). Plot below can be improved.. not sure why we don't get a nice rgb. Also, why is it turned (https://hvplot.holoviz.org/reference/xarray/rgb.html (flip_yaxis should fix it but it doesnt)? Besides, would be nice to show it in correct coordinates (impossible due to rendered preview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51e729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items[0].assets[\"rendered_preview\"].href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a81f5-24f0-43df-942d-f255688b518f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xr.open_dataset(items[0].assets[\"rendered_preview\"].href, engine=\"rasterio\").isel(\n",
    "    {\"band\": slice(0, 3)}\n",
    ")[\"band_data\"].hvplot.rgb(band=\"band\", data_aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e7ed3-1051-47e1-8f4a-1380327bd2b3",
   "metadata": {},
   "source": [
    "### Before I've made RGB plots like this\n",
    "\n",
    "But maybe there is a better way without that xrspatial library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda2893-4e90-44de-ba5b-6fe8e070b8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(items[0].assets[\"rendered_preview\"].href, engine=\"rasterio\").isel(\n",
    "    {\"band\": slice(0, 3)}\n",
    ")[\"band_data\"]\n",
    "\n",
    "rgb = true_color(\n",
    "    ds.isel(band=0),\n",
    "    ds.isel(band=1),\n",
    "    ds.isel(band=2),\n",
    ")\n",
    "\n",
    "rgb.isel({\"band\": slice(0, 3)}).hvplot.rgb(bands=\"band\", y=\"y\", x=\"x\", data_aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63dedd-79a6-49ea-91fe-219e38fffa6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T11:33:39.510661Z",
     "iopub.status.busy": "2023-06-08T11:33:39.510210Z",
     "iopub.status.idle": "2023-06-08T11:33:39.519358Z",
     "shell.execute_reply": "2023-06-08T11:33:39.518416Z",
     "shell.execute_reply.started": "2023-06-08T11:33:39.510637Z"
    },
    "tags": []
   },
   "source": [
    "### How much data do our STAC items refer to?\n",
    " \n",
    "The xarray.DataArray object has a total size of 80.84 GB (gigabytes), which is a very large file size - even though we only have data for a tiny piece of The Netherlands in a 4 month time period. \n",
    "\n",
    "The file size can make it challenging to work with the data on systems with limited storage capacity, but the use of chunking and parallel processing can help to mitigate this issue. The file is chunked into 8 MB (megabyte) blocks, with 10890 chunks in 3 graph layers. This chunking approach is used to enable parallel processing and optimize memory usage when working with large arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e2b9e-38c5-4917-8db7-1b17ba8c87a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackstac.stack(items, resolution=10, assets=list(BAND.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca82c28-2497-4e06-a4a3-eac91d054063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stackstac contains many more arguments to filter the data (on the bounding box, a certain number of bands and by sorting the dates for instance)\n",
    "stack = stackstac.stack(\n",
    "    items,\n",
    "    # epsg=3857,  # if you want to cast the data to a common crs\n",
    "    assets=list(BAND.keys()),\n",
    "    bounds_latlon=bbox,\n",
    "    sortby_date=\"desc\",  # maybe you want to sort the data by date?\n",
    ")\n",
    "stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86168f90-f665-40db-95c5-24396e258793",
   "metadata": {},
   "source": [
    "### EO team discussion point\n",
    "\n",
    "We should discuss how much preprocessing we will include. For example, we could add a few lines to cast the stack from a Xarray DataArray to a Xarray DataSet, which makes it easier to compute spectral indices. However, adding code will make this tutorial notebook longer and more complex - see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414fa99-87a4-49e5-b6dc-87b5890a7dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # overwrite common names from Planetary Computer STAC because they are confusing\n",
    "# stack = stack.assign_coords(common_name=(\"band\", np.array(list(BAND.values()))))\n",
    "\n",
    "# # rename to common names when common names are available\n",
    "# common_names = stack.common_name.where(~stack.common_name.isnull(), stack.band)\n",
    "# stack = stack.where(lambda x: x > 0, other=np.nan).assign_coords(\n",
    "#     band=lambda x: common_names.rename(\"band\"),  # use common names\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140da93-3ad7-463b-946f-783c25a6aece",
   "metadata": {},
   "source": [
    "## 02 - Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72883b8d",
   "metadata": {},
   "source": [
    "### Local Dask cluster\n",
    "\n",
    "Here we launch a local Dask cluster, a Python-based multiprocessing library, which will speed up the computation. The cluster we make here is local, when you want to upscale your computations you should use a Dask gateway, hosted on a remote server, close to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd4631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# when running locally (parallel)\n",
    "client = Client(\n",
    "    threads_per_worker=1,\n",
    "    processes=True,\n",
    "    local_directory=\"/tmp\",\n",
    ")\n",
    "client\n",
    "\n",
    "# asking for plots (.plot()) or numerical values (.compute()) will trigger the computation, which you can see in the dask dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698f1f1",
   "metadata": {},
   "source": [
    "### Example: NDWI\n",
    "Nothing is computed yet. Look at ndwi datarray, they are all dask arrays (lazy). NDWI is used to seperate land and water and forms the basis of shoreline detection algorithms for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b22a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "green = stack.sel({\"band\": \"B03\"})\n",
    "nir = stack.sel({\"band\": \"B08\"})\n",
    "ndwi = (green - nir) / (green + nir)  # this is still a lazy Dask computation\n",
    "ndwi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc974c",
   "metadata": {},
   "source": [
    "By making a plot or computing the values, all scheduled tasks are triggered and the data is brought into memory. This therefore takes somewhat longer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc486d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make plot\n",
    "ndwi.isel({\"time\": 0}).hvplot(x=\"x\", y=\"y\", cmap=cc.CET_D9[::-1], data_aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee971c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute values\n",
    "ndwi_val = ndwi.isel({\"time\": 0}).compute()\n",
    "ndwi_val.shape, ndwi_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a98066",
   "metadata": {},
   "source": [
    "### Example: Compositing (RGB)\n",
    "By compositing, we can get rid of the clouds in individual images. Hence, we create a clean & average image in case we have enough individual images in the data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50248ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "median = stack.median(\"time\")\n",
    "\n",
    "median_rgb = true_color(\n",
    "    median.isel(band=0),\n",
    "    median.isel(band=1),\n",
    "    median.isel(band=2),\n",
    ")\n",
    "median_rgb.isel({\"band\": slice(0, 3)}).hvplot.rgb(\n",
    "    bands=\"band\", y=\"y\", x=\"x\", data_aspect=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3b973",
   "metadata": {},
   "source": [
    "### Example: Scene classification\n",
    "There are many classification algorithms out there, but ESA has incorporated its very own in the Sentinel-2 processing pipeline. This one is readily available as band data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21e4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scl_colormap = np.array(\n",
    "    [\n",
    "        [255, 0, 255, 255],  # 0  - NODATA\n",
    "        [255, 0, 4, 255],  # 1  - Saturated or Defective\n",
    "        [0, 0, 0, 255],  # 2  - Dark Areas\n",
    "        [97, 97, 97, 255],  # 3  - Cloud Shadow\n",
    "        [3, 139, 80, 255],  # 4  - Vegetation\n",
    "        [192, 132, 12, 255],  # 5  - Bare Ground\n",
    "        [21, 103, 141, 255],  # 6  - Water\n",
    "        [117, 0, 27, 255],  # 7  - Unclassified\n",
    "        [208, 208, 208, 255],  # 8  - Cloud\n",
    "        [244, 244, 244, 255],  # 9  - Definitely Cloud\n",
    "        [195, 231, 240, 255],  # 10 - Thin Cloud\n",
    "        [222, 157, 204, 255],  # 11 - Snow or Ice\n",
    "    ],\n",
    "    dtype=\"uint8\",\n",
    ")\n",
    "\n",
    "scl_items = np.array(\n",
    "    [\n",
    "        \"NO DATA\",\n",
    "        \"Saturated or Defective\",\n",
    "        \"Dark areas\",\n",
    "        \"Cloud shadow\",\n",
    "        \"Vegetation\",\n",
    "        \"Bare Ground\",\n",
    "        \"Water\",\n",
    "        \"Unclassified\",\n",
    "        \"Cloud\",\n",
    "        \"Definitely cloud\",\n",
    "        \"Thin cloud\",\n",
    "        \"Snow or ice\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "cmap = ListedColormap(scl_colormap / 255)\n",
    "colors = cmap(np.arange(cmap.N))\n",
    "\n",
    "\n",
    "def colorize(ds, colormap):\n",
    "    return xr.DataArray(colormap[ds.data], coords=ds.coords, dims=(*ds.dims, \"channel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32468e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    1,\n",
    "    figsize=(6, 1),\n",
    "    subplot_kw=dict(xticks=np.arange(0.5, len(scl_colormap), 1), yticks=[]),\n",
    ")\n",
    "ax.imshow([colors], extent=[0, 12, 0, 1])\n",
    "ax.set_xticklabels(scl_items, rotation=30, ha=\"right\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5ad11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCL = stack.isel({\"time\": 0}).sel({\"band\": \"SCL\"})\n",
    "scl_rgba = colorize(SCL.compute().astype(\"int\"), scl_colormap)  # does the computation\n",
    "scl_rgba.hvplot.rgb(x=\"x\", y=\"y\", bands=\"channel\", data_aspect=1)  # does the plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6480e1f4",
   "metadata": {},
   "source": [
    "### More extensive example with other STAC: NDVI\n",
    "Here, we are detecting water hyacinth dynamics in Lake Victoria (specifically the Winam Gulf) using the NDVI. This is done by using the STAC from Digital Earth Africa (DEA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244704f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# water hyacinth in Winam Gulf for the month\n",
    "\n",
    "m = Map(basemap=basemaps.Esri.WorldImagery, scroll_wheel_zoom=True)\n",
    "m.center = -0.14, 34.68\n",
    "m.zoom = 13\n",
    "m.layout.height = \"700px\"\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc681b0f-c662-4736-a1a1-5b46c488f256",
   "metadata": {},
   "source": [
    "## TODO: Explain DEA and their STAC plus loader\n",
    "\n",
    "The DEA STAC contains a number of post-processed datasets that are developed by them, like a mangrove extent layer as part of the Global Mangrove Watch. This STAC is approached differently than the MPC STAC. DEA chose to use the STAC as endpoint for listing or searching metadata. Access could be arranged in their managed analysis sandbox environment with limited computing resources. This has a couple of drawbacks, amongst others the inability of connecting to other datasets. To overcome this, they also provide a Open Data Cube STAC (odc-stac) python package. This consists of a set of tools to access DEA's STAC datasets in your own environment of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80987058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the stac catalogue\n",
    "catalog2 = pystac_client.Client.open(\"https://explorer.digitalearth.africa/stac\")\n",
    "\n",
    "# get the bounding box\n",
    "bbox = [m.west, m.south, m.east, m.north]\n",
    "\n",
    "# change the rasterio configuration\n",
    "configure_rio(\n",
    "    cloud_defaults=True,\n",
    "    aws={\"aws_unsigned\": True},\n",
    "    AWS_S3_ENDPOINT=\"s3.af-south-1.amazonaws.com\",\n",
    ")\n",
    "\n",
    "# Set a start and end date\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2020-01-31\"\n",
    "\n",
    "# Set the STAC collections\n",
    "collections = [\"s2_l2a\"]\n",
    "\n",
    "# Build a query with the set parameters\n",
    "query = catalog2.search(\n",
    "    bbox=bbox, collections=collections, datetime=f\"{start_date}/{end_date}\"\n",
    ")\n",
    "\n",
    "# Search the STAC catalog for all items matching the query\n",
    "items = list(query.get_items())\n",
    "print(f\"Found: {len(items):d} items in the catalog\")\n",
    "\n",
    "# filter out items with cloud cover\n",
    "items = [i for i in items if i.properties[\"eo:cloud_cover\"] < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf326a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set config file for DEA STAC loader\n",
    "config = {\n",
    "    \"s2_l2a\": {\n",
    "        \"assets\": {\n",
    "            \"*\": {\n",
    "                \"data_type\": \"uint16\",\n",
    "                \"nodata\": 0,\n",
    "                \"unit\": \"1\",\n",
    "            },\n",
    "            \"SCL\": {\n",
    "                \"data_type\": \"uint8\",\n",
    "                \"nodata\": 0,\n",
    "                \"unit\": \"1\",\n",
    "            },\n",
    "        },\n",
    "        \"aliases\": {\n",
    "            \"costal_aerosol\": \"B01\",\n",
    "            \"blue\": \"B02\",\n",
    "            \"green\": \"B03\",\n",
    "            \"red\": \"B04\",\n",
    "            \"red_edge_1\": \"B05\",\n",
    "            \"red_edge_2\": \"B06\",\n",
    "            \"red_edge_3\": \"B07\",\n",
    "            \"nir\": \"B08\",\n",
    "            \"nir_narrow\": \"B08A\",\n",
    "            \"water_vapour\": \"B09\",\n",
    "            \"swir_1\": \"B11\",\n",
    "            \"swir_2\": \"B12\",\n",
    "            \"mask\": \"SCL\",\n",
    "            \"aerosol_optical_thickness\": \"AOT\",\n",
    "            \"scene_average_water_vapour\": \"WVP\",\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "crs = \"EPSG:6933\"\n",
    "resolution = 10\n",
    "\n",
    "ds = stac_load(\n",
    "    items,\n",
    "    bands=(\"red\", \"green\", \"blue\", \"nir\"),\n",
    "    crs=crs,\n",
    "    resolution=resolution,\n",
    "    chunks={},\n",
    "    groupby=\"solar_day\",\n",
    "    stac_cfg=config,\n",
    "    bbox=bbox,\n",
    ")\n",
    "\n",
    "# View the Xarray Dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf4c4f-69c3-430d-889e-102738c5567b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEA does no normalization of the sentinel bands\n",
    "red = ds[\"red\"] / 1000\n",
    "nir = ds[\"nir\"] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f2cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute NDVI\n",
    "ndvi = (nir - red) / (nir + red)  # this is still a lazy Dask computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb39b7d-42b9-454c-b052-8b294d48fdcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38989491-9f84-4c31-8e09-6eebab7517bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndvi_da = ndvi.compute()  # make the compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab008e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make plot, this might take a while\n",
    "# compare with: https://www.facebook.com/LocateitLimited/videos/water-hyacinth-earth-observatory-lake-victoria/2757490344316232/\n",
    "ndvi_da.plot(col=\"time\", col_wrap=4, vmin=-0.6, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bb0d8",
   "metadata": {},
   "source": [
    "### EO team TODO:\n",
    "Mask lake area with geojson / shp file (findable on internet?), i.e. getting rid of land area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce179c3-1919-41f4-b4dd-acb1d5598650",
   "metadata": {},
   "source": [
    "create the `pn.widgets.DiscreteSlider` with the time options in the `DataArray`.\n",
    "Bonus: make sure the time shows up formatted in the slider..\n",
    "Then create the callback to visualize one timeslice of the DataFrame.\n",
    "Create a panel `Column`, binding the slider to the callback using `pn.bind`. Make sure to select a good color scheme with limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf88a5-0eb2-49e5-8374-a7bab5d52ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_list = list(map(lambda t: str(t), ndvi_da.time.values))  # format time to str\n",
    "t_slider = pn.widgets.DiscreteSlider(options=time_list, value=time_list[0])\n",
    "\n",
    "\n",
    "def show_time_slice(time_str):\n",
    "    return ndvi_da.sel(time=np.datetime64(time_str)).hvplot(\n",
    "        x=\"x\", y=\"y\", cmap=cc.CET_D9[::-1], clim=(-0.6, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "col = pn.Column(t_slider, pn.bind(show_time_slice, t_slider))\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029005f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make the plot; water hyacinth gets less over time (i.e. open water area grows), meaning mean ndvi goes down\n",
    "df = (\n",
    "    ndvi.mean(dim=[\"x\", \"y\"]).to_dataframe(name=\"ndvi\").reset_index()\n",
    ")  # makes the compute\n",
    "df.hvplot.line(x=\"time\", y=\"ndvi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df89cb9-3bf0-420c-a16f-8d2aa8e4338e",
   "metadata": {},
   "source": [
    "### Small Exercise\n",
    "Can you monitor water hyacinth dynamics for another area in the Winam Gulf by re-using the code above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc9c8f",
   "metadata": {},
   "source": [
    "### Cloud (Dask cluster)\n",
    "\n",
    "Some computations require more power than available on a local (parallelized) cluster. All code shown above is scalable and works in the cloud or at Deltares' own HPC as well when a dask gateway is set up (i.s.o local cluster). This requires access to these remote desktops in advance. For example, you could place your algorithms in the cloud close to where the data is stored, which significantly speeds up your computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5588aff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### More advanced\n",
    "\n",
    "Almost all of xarrays built-in operations work on Dask arrays. Yet, if you want to use a function that isn't wrapped by xarray, one can use `apply_(g)ufunc` or `map_blocks` where you can automate embarrasingly parallel \"map\" type operations from NumPy arrays to Xarray objects with Dask arrays or across all blocks of a Dask array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3c724",
   "metadata": {},
   "source": [
    "When running computations on a Dask cluster (local or cloud), the code needs to be executed on the worker nodes in the cluster. Uploading a Python file to the Dask workers ensures that the required functions and modules are available to the workers when executing the code. This can be achieved by running `client.upload_file(\"xx.py\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0c933-7885-4100-ab94-260591c1082f",
   "metadata": {},
   "source": [
    "## 03 - Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5869a",
   "metadata": {},
   "source": [
    "### Holoviz Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634e13d-a49b-4585-bf65-2910431869de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = stack.copy().compute()\n",
    "ds.coords[\"time\"] = pd.DatetimeIndex(ds[\"time\"]).strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "time_options = ds.coords[\"time\"].values.tolist()\n",
    "time_slider = pn.widgets.DiscreteSlider(name=\"Time\", options=time_options)\n",
    "\n",
    "\n",
    "@pn.depends(time_slider.param.value)\n",
    "def plot_rgb(time, **kwargs):\n",
    "    rgb = (\n",
    "        true_color(*ds.sel({\"time\": time}).isel({\"band\": slice(0, 3)}))\n",
    "        .isel({\"band\": slice(0, 3)})\n",
    "        .hvplot.rgb(bands=\"band\", y=\"y\", x=\"x\")\n",
    "    )\n",
    "    return rgb.opts(title=f\"RGB of {time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04234d6e-0703-4d34-b3ab-03105fc0adea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pn.extension()\n",
    "title_bar = pn.Row(\n",
    "    pn.pane.Markdown(\n",
    "        \"## Interactive Earth Observation dashboard\",\n",
    "        styles={\"color\": \"black\"},\n",
    "        width=800,\n",
    "        sizing_mode=\"fixed\",\n",
    "        margin=(10, 5, 10, 15),\n",
    "    ),\n",
    "    pn.Spacer(),\n",
    ")\n",
    "eo_panel = pn.Column(title_bar, pn.Row(time_slider), pn.Row(plot_rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0be28-1f3d-4903-9171-31c3d93ffd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eo_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec3286",
   "metadata": {},
   "source": [
    "### QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3673a3-95fb-484c-8dff-84615be58f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for QGIS; export the TIFF to be visualized (CoG)\n",
    "outdir = proj_dir / \"tmp\"\n",
    "if not outdir.exists():\n",
    "    outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "to_save = stack.isel({\"time\": 0})\n",
    "fname = f\"IMG-{to_save.time.dt.strftime('%Y%m%d').item()}.tif\"\n",
    "outpath = outdir / fname\n",
    "to_save.rio.to_raster(raster_path=outpath, driver=\"COG\")\n",
    "print(f\"Saving to: '{outpath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close down local cluster\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysense]",
   "language": "python",
   "name": "conda-env-pysense-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
